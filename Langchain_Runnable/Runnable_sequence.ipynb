{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain.schema.runnable import RunnableSequence"
      ],
      "metadata": {
        "id": "76ezUDi96Bkd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt1 = PromptTemplate(\n",
        "    template=\"write a joke about {topic}\",\n",
        "    input_variables=[\"topic\"]\n",
        ")"
      ],
      "metadata": {
        "id": "B3uPXKj97B-e"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGroq(\n",
        "     groq_api_key=\"gsk_234ecOmFPNNjlhCDDPurqTJgK2r5yBzND\",\n",
        "     model=\"llama3-8b-8192\"\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "6ShOi8Vh8dNO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser = StrOutputParser()"
      ],
      "metadata": {
        "id": "dwPhX8c_89Qq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt2 = PromptTemplate(\n",
        "    template='Explain the following joke - {text}',\n",
        "    input_variables=['text']\n",
        ")"
      ],
      "metadata": {
        "id": "vHMaG9tC8vx3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = RunnableSequence(prompt1, llm, parser, prompt2, llm, parser)"
      ],
      "metadata": {
        "id": "a4gaBK0_9Dib"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain.invoke({'topic':'AI'}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrKk8ZwE9O5m",
        "outputId": "bfe2f04d-372c-4a63-8590-8d2437baec8f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A classic tech-themed joke!\n",
            "\n",
            "The joke is a play on words, using a pun to create humor. Here's how it works:\n",
            "\n",
            "* \"Go on a diet\" is a common phrase that refers to a person's decision to lose weight by eating less and exercising more.\n",
            "* \"Lose some bytes\" is a pun that replaces \"weight\" with \"bytes\". In computing, a \"byte\" is a unit of digital information, equivalent to a single character or a group of bits.\n",
            "* The joke is saying that the AI program went on a diet, but instead of losing weight, it wants to \"lose some bytes\", implying that it wants to reduce its digital size or storage requirements. It's a clever and humorous way to connect the concept of dieting with the digital world.\n",
            "\n",
            "Overall, the joke relies on the listener being familiar with both the concept of dieting and the basics of computer terminology, which adds to the cleverness and humor of the pun.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.get_graph().print_ascii()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjmTK7Sv9Vty",
        "outputId": "3784846c-6f5f-4175-f124-d3f5b3af4c27"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     +-------------+       \n",
            "     | PromptInput |       \n",
            "     +-------------+       \n",
            "            *              \n",
            "            *              \n",
            "            *              \n",
            "    +----------------+     \n",
            "    | PromptTemplate |     \n",
            "    +----------------+     \n",
            "            *              \n",
            "            *              \n",
            "            *              \n",
            "      +----------+         \n",
            "      | ChatGroq |         \n",
            "      +----------+         \n",
            "            *              \n",
            "            *              \n",
            "            *              \n",
            "   +-----------------+     \n",
            "   | StrOutputParser |     \n",
            "   +-----------------+     \n",
            "            *              \n",
            "            *              \n",
            "            *              \n",
            "+-----------------------+  \n",
            "| StrOutputParserOutput |  \n",
            "+-----------------------+  \n",
            "            *              \n",
            "            *              \n",
            "            *              \n",
            "    +----------------+     \n",
            "    | PromptTemplate |     \n",
            "    +----------------+     \n",
            "            *              \n",
            "            *              \n",
            "            *              \n",
            "      +----------+         \n",
            "      | ChatGroq |         \n",
            "      +----------+         \n",
            "            *              \n",
            "            *              \n",
            "            *              \n",
            "   +-----------------+     \n",
            "   | StrOutputParser |     \n",
            "   +-----------------+     \n",
            "            *              \n",
            "            *              \n",
            "            *              \n",
            "+-----------------------+  \n",
            "| StrOutputParserOutput |  \n",
            "+-----------------------+  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install grandalf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uY-jySgN9eBc",
        "outputId": "761ec241-bfe9-44fa-839d-a1ca413b948e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting grandalf\n",
            "  Downloading grandalf-0.8-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from grandalf) (3.2.3)\n",
            "Downloading grandalf-0.8-py3-none-any.whl (41 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: grandalf\n",
            "Successfully installed grandalf-0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XIaJ9Jw29itX"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UBHKfr4t915t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}