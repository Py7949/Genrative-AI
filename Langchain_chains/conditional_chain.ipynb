{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain.schema.runnable import RunnableParallel, RunnableBranch, RunnableLambda\n",
        "from langchain_core.output_parsers import PydanticOutputParser\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import Literal\n"
      ],
      "metadata": {
        "id": "yQ1eD2IYpOph"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm1= ChatGroq(\n",
        "    groq_api_key=\"gsk_13NEXVpBau9nFY8a0FNoNjfRZzctkOyZGRdji0\",\n",
        "     model=\"llama3-8b-8192\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "0LLgtnI7qK_T"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser = StrOutputParser()"
      ],
      "metadata": {
        "id": "W8lcEkVr0NsR"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class feedback(BaseModel):\n",
        "    sentiment: Literal['positive', 'negative'] = Field(\n",
        "        description='Give the sentiment of the feedback, either \"positive\" or \"negative\"',\n",
        "        examples=['positive']\n",
        "    )\n"
      ],
      "metadata": {
        "id": "p4CghqDr0aBI"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser2 = PydanticOutputParser(pydantic_object=feedback)"
      ],
      "metadata": {
        "id": "c_6O4H9C1Ki9"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt1 = PromptTemplate(\n",
        "    template='Classify the sentiment of the following feedback text into postive or negative \\n {feedback} \\n {format_instruction}',\n",
        "    input_variables=['feedback'],\n",
        "    partial_variables={'format_instruction':parser2.get_format_instructions()}\n",
        ")"
      ],
      "metadata": {
        "id": "RhAmBa5-1hHw"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_chain = prompt1 | llm1 | parser2"
      ],
      "metadata": {
        "id": "M0xUk6TW1kk1"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt2 = PromptTemplate(\n",
        "    template='Write an appropriate response to this positive feedback \\n {feedback}',\n",
        "    input_variables=['feedback']\n",
        ")"
      ],
      "metadata": {
        "id": "txqGGaDV1_zq"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt3 = PromptTemplate(\n",
        "    template='Write an appropriate response to this negative feedback \\n {feedback}',\n",
        "    input_variables=['feedback']\n",
        ")\n"
      ],
      "metadata": {
        "id": "YxjewuyK2FNN"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "branch_chain = RunnableBranch(\n",
        "    (lambda x:x.sentiment == 'positive', prompt2 | llm1 | parser),\n",
        "    (lambda x:x.sentiment == 'negative', prompt3 | llm1 | parser),\n",
        "    RunnableLambda(lambda x: \"could not find sentiment\")\n",
        ")"
      ],
      "metadata": {
        "id": "5MjiTqtZ2KJ0"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = classifier_chain | branch_chain"
      ],
      "metadata": {
        "id": "sYjUSOei2XBu"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain.invoke({'feedback': 'This is a beautiful phone'}))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pxbXNsk2epE",
        "outputId": "b8f74e00-c43b-4eb8-f7fe-709ef438bdb8"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a response to positive feedback:\n",
            "\n",
            "\"Thank you so much for taking the time to share your kind words! I'm thrilled to hear that you're satisfied with [specific aspect of service/product]. It's always our goal to provide the best possible experience for our customers, and I'm glad to see that we were able to meet your expectations. Your feedback is invaluable to us, and I'll make sure to pass it along to the team. Thank you again for your enthusiasm and loyalty - we appreciate it!\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.get_graph().print_ascii()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8N43K7S2nTI",
        "outputId": "681c3724-5f05-4b53-ad23-a0c80d59bbaf"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    +-------------+      \n",
            "    | PromptInput |      \n",
            "    +-------------+      \n",
            "            *            \n",
            "            *            \n",
            "            *            \n",
            "   +----------------+    \n",
            "   | PromptTemplate |    \n",
            "   +----------------+    \n",
            "            *            \n",
            "            *            \n",
            "            *            \n",
            "      +----------+       \n",
            "      | ChatGroq |       \n",
            "      +----------+       \n",
            "            *            \n",
            "            *            \n",
            "            *            \n",
            "+----------------------+ \n",
            "| PydanticOutputParser | \n",
            "+----------------------+ \n",
            "            *            \n",
            "            *            \n",
            "            *            \n",
            "       +--------+        \n",
            "       | Branch |        \n",
            "       +--------+        \n",
            "            *            \n",
            "            *            \n",
            "            *            \n",
            "    +--------------+     \n",
            "    | BranchOutput |     \n",
            "    +--------------+     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JCdcu2r74IvE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}